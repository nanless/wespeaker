#!/usr/bin/env python3
"""
è¯´è¯äººç›¸ä¼¼åº¦è®¡ç®—æ¼”ç¤ºè„šæœ¬
å±•ç¤ºç›¸ä¼¼åº¦è®¡ç®—çš„è¯¦ç»†è¿‡ç¨‹å’ŒåŽŸç†
"""

import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt
import seaborn as sns

def manual_cosine_similarity(vec1, vec2):
    """æ‰‹åŠ¨è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œå±•ç¤ºè®¡ç®—è¿‡ç¨‹"""
    print("ðŸ” æ‰‹åŠ¨è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦è¿‡ç¨‹:")
    print(f"å‘é‡A: {vec1}")
    print(f"å‘é‡B: {vec2}")
    
    # è®¡ç®—ç‚¹ç§¯
    dot_product = np.dot(vec1, vec2)
    print(f"ç‚¹ç§¯: {dot_product:.4f}")
    
    # è®¡ç®—L2èŒƒæ•°
    norm_a = np.linalg.norm(vec1)
    norm_b = np.linalg.norm(vec2)
    print(f"||A||: {norm_a:.4f}")
    print(f"||B||: {norm_b:.4f}")
    
    # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    cosine_sim = dot_product / (norm_a * norm_b)
    print(f"ä½™å¼¦ç›¸ä¼¼åº¦: {cosine_sim:.4f}")
    
    return cosine_sim

def demonstrate_similarity_calculation():
    """æ¼”ç¤ºç›¸ä¼¼åº¦è®¡ç®—"""
    print("=" * 60)
    print("è¯´è¯äººç›¸ä¼¼åº¦è®¡ç®—æ¼”ç¤º")
    print("=" * 60)
    
    # æ¨¡æ‹Ÿä¸¤ä¸ªè¯´è¯äººçš„embedding
    print("\nðŸ“Š ç¤ºä¾‹1: é«˜ç›¸ä¼¼åº¦è¯´è¯äºº")
    speaker_A = np.array([0.5, 0.8, 0.1, 0.6])
    speaker_B = np.array([0.4, 0.9, 0.2, 0.5])
    
    manual_sim = manual_cosine_similarity(speaker_A, speaker_B)
    sklearn_sim = cosine_similarity([speaker_A], [speaker_B])[0][0]
    print(f"sklearnç»“æžœ: {sklearn_sim:.4f}")
    print(f"å·®å¼‚: {abs(manual_sim - sklearn_sim):.6f}")
    
    print("\nðŸ“Š ç¤ºä¾‹2: ä½Žç›¸ä¼¼åº¦è¯´è¯äºº")
    speaker_C = np.array([0.1, 0.2, 0.9, 0.1])
    speaker_D = np.array([0.9, 0.1, 0.1, 0.8])
    
    manual_sim2 = manual_cosine_similarity(speaker_C, speaker_D)
    sklearn_sim2 = cosine_similarity([speaker_C], [speaker_D])[0][0]
    print(f"sklearnç»“æžœ: {sklearn_sim2:.4f}")
    
    print("\nðŸ“Š ç¤ºä¾‹3: å®Œå…¨ç›¸åŒçš„è¯´è¯äºº")
    manual_sim3 = manual_cosine_similarity(speaker_A, speaker_A)
    print(f"è‡ªç›¸ä¼¼åº¦: {manual_sim3:.4f}")

def simulate_speaker_embeddings(num_speakers=5, embedding_dim=4):
    """æ¨¡æ‹Ÿç”Ÿæˆè¯´è¯äººembeddings"""
    print(f"\nðŸŽ­ æ¨¡æ‹Ÿ {num_speakers} ä¸ªè¯´è¯äººçš„ {embedding_dim} ç»´embedding")
    
    # ç”Ÿæˆéšæœºembeddings
    np.random.seed(42)  # ç¡®ä¿å¯é‡å¤
    embeddings = {}
    
    for i in range(num_speakers):
        # æ¨¡æ‹ŸçœŸå®žembeddingçš„åˆ†å¸ƒç‰¹æ€§
        embedding = np.random.normal(0.5, 0.2, embedding_dim)
        embedding = np.clip(embedding, 0, 1)  # é™åˆ¶åœ¨[0,1]èŒƒå›´
        embeddings[f'speaker_{i+1}'] = embedding
        print(f"è¯´è¯äºº{i+1}: {embedding}")
    
    return embeddings

def compute_similarity_matrix(embeddings):
    """è®¡ç®—å®Œæ•´çš„ç›¸ä¼¼åº¦çŸ©é˜µ"""
    print("\nðŸ“ˆ è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ...")
    
    speaker_names = list(embeddings.keys())
    embedding_matrix = np.array(list(embeddings.values()))
    
    # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
    similarity_matrix = cosine_similarity(embedding_matrix)
    
    print("ç›¸ä¼¼åº¦çŸ©é˜µ:")
    print("=" * 50)
    
    # æ‰“å°è¡¨å¤´
    print(f"{'':12}", end='')
    for name in speaker_names:
        print(f"{name:12}", end='')
    print()
    
    # æ‰“å°çŸ©é˜µå†…å®¹
    for i, name in enumerate(speaker_names):
        print(f"{name:12}", end='')
        for j in range(len(speaker_names)):
            print(f"{similarity_matrix[i][j]:12.4f}", end='')
        print()
    
    return similarity_matrix, speaker_names

def analyze_similarities(similarity_matrix, speaker_names):
    """åˆ†æžç›¸ä¼¼åº¦ç»“æžœ"""
    print("\nðŸ” ç›¸ä¼¼åº¦åˆ†æž:")
    print("=" * 40)
    
    # æ‰¾åˆ°æœ€ç›¸ä¼¼çš„pair (æŽ’é™¤è‡ªå·±å’Œè‡ªå·±)
    max_sim = 0
    max_pair = None
    min_sim = 1
    min_pair = None
    
    n = len(speaker_names)
    for i in range(n):
        for j in range(i+1, n):  # åªçœ‹ä¸Šä¸‰è§’çŸ©é˜µ
            sim = similarity_matrix[i][j]
            if sim > max_sim:
                max_sim = sim
                max_pair = (speaker_names[i], speaker_names[j])
            if sim < min_sim:
                min_sim = sim
                min_pair = (speaker_names[i], speaker_names[j])
    
    print(f"æœ€ç›¸ä¼¼çš„è¯´è¯äººå¯¹: {max_pair[0]} vs {max_pair[1]}")
    print(f"ç›¸ä¼¼åº¦: {max_sim:.4f}")
    print(f"æœ€ä¸ç›¸ä¼¼çš„è¯´è¯äººå¯¹: {min_pair[0]} vs {min_pair[1]}")
    print(f"ç›¸ä¼¼åº¦: {min_sim:.4f}")
    
    # ç›¸ä¼¼åº¦åˆ†å¸ƒç»Ÿè®¡
    upper_triangle = similarity_matrix[np.triu_indices(n, k=1)]
    print(f"\nç›¸ä¼¼åº¦ç»Ÿè®¡:")
    print(f"å¹³å‡ç›¸ä¼¼åº¦: {np.mean(upper_triangle):.4f}")
    print(f"æ ‡å‡†å·®: {np.std(upper_triangle):.4f}")
    print(f"æœ€å¤§ç›¸ä¼¼åº¦: {np.max(upper_triangle):.4f}")
    print(f"æœ€å°ç›¸ä¼¼åº¦: {np.min(upper_triangle):.4f}")

def demonstrate_utterance_aggregation():
    """æ¼”ç¤ºè¯´è¯äººutteranceèšåˆè¿‡ç¨‹"""
    print("\nðŸŽ¤ æ¼”ç¤ºè¯´è¯äººutteranceèšåˆ")
    print("=" * 40)
    
    # æ¨¡æ‹Ÿä¸€ä¸ªè¯´è¯äººçš„å¤šä¸ªutterance embeddings
    utterance_embeddings = [
        np.array([0.5, 0.8, 0.1, 0.6]),
        np.array([0.4, 0.9, 0.2, 0.5]),
        np.array([0.6, 0.7, 0.1, 0.7]),
        np.array([0.3, 0.8, 0.3, 0.4])
    ]
    
    print("åŽŸå§‹utterance embeddings:")
    for i, emb in enumerate(utterance_embeddings):
        print(f"  Utterance {i+1}: {emb}")
    
    # è®¡ç®—å¹³å‡embedding
    avg_embedding = np.mean(utterance_embeddings, axis=0)
    print(f"\nå¹³å‡embedding: {avg_embedding}")
    
    # åˆ†æžèšåˆæ•ˆæžœ
    print(f"\nèšåˆåˆ†æž:")
    original_matrix = np.array(utterance_embeddings)
    print(f"åŽŸå§‹embeddingæ ‡å‡†å·®: {np.std(original_matrix, axis=0)}")
    print(f"å¹³å‡å€¼: {np.mean(original_matrix, axis=0)}")
    
    # è®¡ç®—utteranceä¹‹é—´çš„ç›¸ä¼¼åº¦
    print(f"\nUtteranceé—´ç›¸ä¼¼åº¦:")
    for i in range(len(utterance_embeddings)):
        for j in range(i+1, len(utterance_embeddings)):
            sim = cosine_similarity([utterance_embeddings[i]], [utterance_embeddings[j]])[0][0]
            print(f"  Utterance {i+1} vs {j+1}: {sim:.4f}")

def demonstrate_boundary_detection_similarity():
    """æ¼”ç¤ºè¾¹ç•Œæ£€æµ‹ä¸­çš„ç›¸ä¼¼åº¦åº”ç”¨"""
    print("\nðŸŽ¯ æ¼”ç¤ºè¾¹ç•Œæ£€æµ‹ç›¸ä¼¼åº¦åº”ç”¨")
    print("=" * 40)
    
    # æ¨¡æ‹ŸéŸ³é¢‘sequenceçš„embeddings
    # å‰5ä¸ªå±žäºŽè¯´è¯äººAï¼ŒåŽ5ä¸ªå±žäºŽè¯´è¯äººB
    speaker_A_embeddings = [
        np.array([0.8, 0.2, 0.1, 0.9]) + np.random.normal(0, 0.05, 4)
        for _ in range(5)
    ]
    speaker_B_embeddings = [
        np.array([0.2, 0.8, 0.9, 0.1]) + np.random.normal(0, 0.05, 4)
        for _ in range(5)
    ]
    
    all_embeddings = np.array(speaker_A_embeddings + speaker_B_embeddings)
    
    # è®¡ç®—æ®µä¸­å¿ƒ
    left_center = np.mean(speaker_A_embeddings, axis=0)
    right_center = np.mean(speaker_B_embeddings, axis=0)
    
    print(f"å·¦æ®µä¸­å¿ƒ (è¯´è¯äººA): {left_center}")
    print(f"å³æ®µä¸­å¿ƒ (è¯´è¯äººB): {right_center}")
    print(f"æ®µé—´ç›¸ä¼¼åº¦: {cosine_similarity([left_center], [right_center])[0][0]:.4f}")
    
    # æµ‹è¯•ä¸åŒè¾¹ç•Œä½ç½®çš„è´¨é‡
    print(f"\nè¾¹ç•Œä½ç½®è¯„ä¼°:")
    for boundary in range(3, 8):  # æµ‹è¯•è¾¹ç•Œä½ç½®3-7
        # è®¡ç®—å·¦ä¾§ä¸Žå·¦ä¸­å¿ƒçš„ç›¸ä¼¼åº¦
        left_sims = [cosine_similarity([emb], [left_center])[0][0] 
                     for emb in all_embeddings[:boundary]]
        left_avg = np.mean(left_sims)
        
        # è®¡ç®—å³ä¾§ä¸Žå³ä¸­å¿ƒçš„ç›¸ä¼¼åº¦
        right_sims = [cosine_similarity([emb], [right_center])[0][0] 
                      for emb in all_embeddings[boundary:]]
        right_avg = np.mean(right_sims)
        
        # è¾¹ç•Œè´¨é‡å¾—åˆ†
        boundary_score = left_avg + right_avg
        
        print(f"  è¾¹ç•Œä½ç½® {boundary}: å·¦ä¾§ç›¸ä¼¼åº¦ {left_avg:.4f}, å³ä¾§ç›¸ä¼¼åº¦ {right_avg:.4f}, æ€»åˆ† {boundary_score:.4f}")

def create_similarity_visualization(similarity_matrix, speaker_names):
    """åˆ›å»ºç›¸ä¼¼åº¦å¯è§†åŒ–å›¾"""
    try:
        plt.figure(figsize=(10, 8))
        
        # åˆ›å»ºçƒ­åŠ›å›¾
        sns.heatmap(similarity_matrix, 
                   xticklabels=speaker_names, 
                   yticklabels=speaker_names,
                   annot=True, 
                   fmt='.3f',
                   cmap='viridis',
                   square=True)
        
        plt.title('è¯´è¯äººç›¸ä¼¼åº¦çŸ©é˜µ')
        plt.xlabel('è¯´è¯äºº')
        plt.ylabel('è¯´è¯äºº')
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        output_file = 'examples/extract_and_conclude_similarities/v2/similarity_matrix_demo.png'
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"\nðŸ“Š ç›¸ä¼¼åº¦çŸ©é˜µå¯è§†åŒ–å·²ä¿å­˜: {output_file}")
        plt.close()
        
    except Exception as e:
        print(f"\nâš ï¸ å¯è§†åŒ–åˆ›å»ºå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ðŸŽ™ï¸ è¯´è¯äººç›¸ä¼¼åº¦è®¡ç®—æ¼”ç¤ºç¨‹åº")
    print("è¯¦ç»†å±•ç¤ºç›¸ä¼¼åº¦è®¡ç®—çš„æ•°å­¦åŽŸç†å’Œå®žé™…åº”ç”¨\n")
    
    # 1. åŸºç¡€ç›¸ä¼¼åº¦è®¡ç®—æ¼”ç¤º
    demonstrate_similarity_calculation()
    
    # 2. æ¨¡æ‹Ÿè¯´è¯äººembeddings
    embeddings = simulate_speaker_embeddings(num_speakers=6, embedding_dim=8)
    
    # 3. è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
    similarity_matrix, speaker_names = compute_similarity_matrix(embeddings)
    
    # 4. åˆ†æžç›¸ä¼¼åº¦ç»“æžœ
    analyze_similarities(similarity_matrix, speaker_names)
    
    # 5. æ¼”ç¤ºutteranceèšåˆ
    demonstrate_utterance_aggregation()
    
    # 6. æ¼”ç¤ºè¾¹ç•Œæ£€æµ‹åº”ç”¨
    demonstrate_boundary_detection_similarity()
    
    # 7. åˆ›å»ºå¯è§†åŒ–
    create_similarity_visualization(similarity_matrix, speaker_names)
    
    print("\n" + "=" * 60)
    print("âœ… æ¼”ç¤ºå®Œæˆï¼")
    print("ðŸ’¡ å…³é”®è¦ç‚¹:")
    print("  1. ç›¸ä¼¼åº¦ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—")
    print("  2. å–å€¼èŒƒå›´ [0, 1]ï¼Œè¶ŠæŽ¥è¿‘1è¶Šç›¸ä¼¼")
    print("  3. è¯´è¯äººembeddingé€šè¿‡utteranceå¹³å‡èŽ·å¾—")
    print("  4. å¯ç”¨äºŽè¯´è¯äººè¯†åˆ«ã€èšç±»ã€è¾¹ç•Œæ£€æµ‹ç­‰ä»»åŠ¡")
    print("=" * 60)

if __name__ == "__main__":
    main()