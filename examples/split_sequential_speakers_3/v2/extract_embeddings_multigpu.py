#!/usr/bin/env python3
"""
å¤šGPUéŸ³é¢‘embeddingæå–è„šæœ¬
å°†æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶æå–ä¸ºembeddingå¹¶ä¿å­˜ä¸ºå•ç‹¬çš„æ–‡ä»¶
ç›®å½•ç»“æž„ä¸ŽåŽŸéŸ³é¢‘æ–‡ä»¶ä¿æŒä¸€è‡´
"""

import os
import sys
import json
import numpy as np
import argparse
from pathlib import Path
import torch
import torch.distributed as dist
import torch.multiprocessing as mp
from tqdm import tqdm
import time
import pickle

# æ·»åŠ WeSpeakerè·¯å¾„
wespeaker_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../../'))
sys.path.insert(0, wespeaker_root)

try:
    from wespeaker.cli.speaker import load_model_local
    print("âœ… æˆåŠŸå¯¼å…¥wespeakeræ¨¡å—")
except ImportError as e:
    print(f"âŒ å¯¼å…¥wespeakeræ¨¡å—å¤±è´¥: {e}")
    sys.exit(1)

def setup(rank, world_size, port='12355'):
    """è®¾ç½®åˆ†å¸ƒå¼çŽ¯å¢ƒ"""
    os.environ['MASTER_ADDR'] = 'localhost'
    os.environ['MASTER_PORT'] = port
    dist.init_process_group("nccl", rank=rank, world_size=world_size)

def cleanup():
    """æ¸…ç†åˆ†å¸ƒå¼çŽ¯å¢ƒ"""
    if dist.is_initialized():
        dist.destroy_process_group()

def scan_audio_files(input_dir):
    """æ‰«ææ‰€æœ‰éŸ³é¢‘æ–‡ä»¶å¹¶ä¿æŒç›®å½•ç»“æž„"""
    audio_files = []
    audio_extensions = {'.wav', '.mp3', '.flac', '.m4a'}
    
    print(f"ðŸ“‚ æ‰«æéŸ³é¢‘æ–‡ä»¶: {input_dir}")
    
    for root, dirs, files in os.walk(input_dir):
        for file in files:
            if Path(file).suffix.lower() in audio_extensions:
                full_path = os.path.join(root, file)
                # è®¡ç®—ç›¸å¯¹è·¯å¾„ï¼Œç”¨äºŽä¿æŒç›®å½•ç»“æž„
                rel_path = os.path.relpath(full_path, input_dir)
                audio_files.append({
                    'full_path': full_path,
                    'relative_path': rel_path,
                    'filename': file
                })
    
    print(f"ðŸ“Š æ‰¾åˆ° {len(audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶")
    return audio_files

def extract_embeddings_on_gpu(rank, world_size, args, audio_files):
    """åœ¨ç‰¹å®šGPUä¸Šæå–embeddings"""
    setup(rank, world_size, args.port)
    
    print(f"ðŸ–¥ï¸ GPU {rank}: å¼€å§‹åŠ è½½æ¨¡åž‹...")
    
    try:
        # åŠ è½½æ¨¡åž‹åˆ°ç‰¹å®šGPU
        speaker_model = load_model_local(args.model_dir)
        speaker_model.set_device(f'cuda:{rank}')
        
        # è®¡ç®—è¿™ä¸ªGPUéœ€è¦å¤„ç†çš„æ–‡ä»¶èŒƒå›´
        total_files = len(audio_files)
        files_per_gpu = (total_files + world_size - 1) // world_size
        start_idx = rank * files_per_gpu
        end_idx = min(start_idx + files_per_gpu, total_files)
        
        gpu_audio_files = audio_files[start_idx:end_idx]
        
        print(f"ðŸŽ¯ GPU {rank}: å¤„ç†æ–‡ä»¶ {start_idx}-{end_idx-1} ({len(gpu_audio_files)} ä¸ªæ–‡ä»¶)")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(args.output_dir, exist_ok=True)
        
        # æå–embeddings
        success_count = 0
        failed_count = 0
        
        for audio_info in tqdm(gpu_audio_files, desc=f"GPU {rank} æå–embedding"):
            try:
                audio_path = audio_info['full_path']
                relative_path = audio_info['relative_path']
                
                if not os.path.exists(audio_path):
                    print(f"âš ï¸ GPU {rank}: æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
                    failed_count += 1
                    continue
                
                # æå–embedding
                embedding = speaker_model.extract_embedding(audio_path)
                
                if embedding is not None:
                    # æž„å»ºè¾“å‡ºè·¯å¾„ï¼Œä¿æŒç›®å½•ç»“æž„
                    output_rel_path = Path(relative_path).with_suffix('.pkl')
                    output_path = os.path.join(args.output_dir, output_rel_path)
                    
                    # åˆ›å»ºè¾“å‡ºç›®å½•
                    os.makedirs(os.path.dirname(output_path), exist_ok=True)
                    
                    # ä¿å­˜embeddingå’Œå…ƒæ•°æ®
                    embedding_data = {
                        'embedding': embedding,
                        'original_path': audio_path,
                        'relative_path': relative_path,
                        'filename': audio_info['filename'],
                        'embedding_dim': len(embedding),
                        'gpu_rank': rank
                    }
                    
                    with open(output_path, 'wb') as f:
                        pickle.dump(embedding_data, f)
                    
                    success_count += 1
                else:
                    print(f"âŒ GPU {rank}: æå–embeddingå¤±è´¥: {audio_path}")
                    failed_count += 1
                    
            except Exception as e:
                print(f"âŒ GPU {rank}: å¤„ç†æ–‡ä»¶å‡ºé”™ {audio_info['full_path']}: {e}")
                failed_count += 1
                continue
        
        print(f"âœ… GPU {rank}: å®Œæˆå¤„ç†ï¼ŒæˆåŠŸ {success_count} ä¸ªï¼Œå¤±è´¥ {failed_count} ä¸ª")
        
        # ä¿å­˜GPUå¤„ç†ç»“æžœç»Ÿè®¡
        stats = {
            'gpu_rank': rank,
            'total_processed': len(gpu_audio_files),
            'success_count': success_count,
            'failed_count': failed_count,
            'start_idx': start_idx,
            'end_idx': end_idx
        }
        
        stats_file = os.path.join(args.output_dir, f'gpu_{rank}_stats.json')
        with open(stats_file, 'w') as f:
            json.dump(stats, f, indent=2)
        
    except Exception as e:
        print(f"âŒ GPU {rank}: å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
    finally:
        cleanup()

def merge_gpu_stats(output_dir, world_size):
    """åˆå¹¶æ‰€æœ‰GPUçš„ç»Ÿè®¡ä¿¡æ¯"""
    print("ðŸ”„ åˆå¹¶GPUç»Ÿè®¡ä¿¡æ¯...")
    
    total_stats = {
        'total_files': 0,
        'total_success': 0,
        'total_failed': 0,
        'gpu_stats': []
    }
    
    for rank in range(world_size):
        stats_file = os.path.join(output_dir, f'gpu_{rank}_stats.json')
        if os.path.exists(stats_file):
            with open(stats_file, 'r') as f:
                gpu_stats = json.load(f)
            
            total_stats['total_files'] += gpu_stats['total_processed']
            total_stats['total_success'] += gpu_stats['success_count']
            total_stats['total_failed'] += gpu_stats['failed_count']
            total_stats['gpu_stats'].append(gpu_stats)
            
            # åˆ é™¤ä¸´æ—¶ç»Ÿè®¡æ–‡ä»¶
            os.remove(stats_file)
    
    # ä¿å­˜åˆå¹¶åŽçš„ç»Ÿè®¡ä¿¡æ¯
    final_stats_file = os.path.join(output_dir, 'extraction_stats.json')
    with open(final_stats_file, 'w') as f:
        json.dump(total_stats, f, indent=2)
    
    print(f"ðŸ“Š æ€»ä½“ç»Ÿè®¡: å¤„ç† {total_stats['total_files']} ä¸ªæ–‡ä»¶")
    print(f"   æˆåŠŸ: {total_stats['total_success']} ä¸ª")
    print(f"   å¤±è´¥: {total_stats['total_failed']} ä¸ª")
    print(f"   æˆåŠŸçŽ‡: {total_stats['total_success']/total_stats['total_files']*100:.1f}%")

def main():
    parser = argparse.ArgumentParser(description="å¤šGPUéŸ³é¢‘embeddingæå–")
    parser.add_argument('--input_dir', type=str, default="/root/group-shared/voiceprint/data/speech/speech_enhancement/child-2.07M/wav_files",
                       help='è¾“å…¥éŸ³é¢‘ç›®å½•è·¯å¾„')
    parser.add_argument('--output_dir', type=str, default="/root/group-shared/voiceprint/data/speech/speech_enhancement/child-2.07M/wav_embeddings_samresnet100",
                       help='è¾“å‡ºembeddingç›®å½•è·¯å¾„')
    parser.add_argument('--model_dir', type=str, default="/root/workspace/speaker_verification/mix_adult_kid/exp/voxblink2_samresnet100",
                       help='è¯´è¯äººæ¨¡åž‹ç›®å½•è·¯å¾„')
    parser.add_argument('--gpus', type=str, default="0,1,2,3",
                       help='ä½¿ç”¨çš„GPUåˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš” (e.g., "0,1,2,3"). å¦‚æžœä¸æŒ‡å®šåˆ™ä½¿ç”¨æ‰€æœ‰å¯ç”¨GPU')
    parser.add_argument('--port', type=str, default='12355',
                       help='åˆ†å¸ƒå¼é€šä¿¡ç«¯å£')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥ç›®å½•
    if not os.path.exists(args.input_dir):
        print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {args.input_dir}")
        return
    
    # æ£€æŸ¥æ¨¡åž‹ç›®å½•
    if not os.path.exists(args.model_dir):
        print(f"âŒ æ¨¡åž‹ç›®å½•ä¸å­˜åœ¨: {args.model_dir}")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    
    # æ‰«æéŸ³é¢‘æ–‡ä»¶
    audio_files = scan_audio_files(args.input_dir)
    
    if not audio_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶")
        return
    
    # è®¾ç½®GPUé…ç½®
    if args.gpus is not None:
        os.environ["CUDA_VISIBLE_DEVICES"] = args.gpus
        available_gpus = [int(x) for x in args.gpus.split(',')]
        world_size = len(available_gpus)
    else:
        world_size = torch.cuda.device_count()
        available_gpus = list(range(world_size))
    
    if world_size == 0:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„GPU!")
        return
    
    print(f"ðŸ–¥ï¸ ä½¿ç”¨ {world_size} ä¸ªGPU: {available_gpus}")
    print(f"ðŸ“ è¾“å…¥ç›®å½•: {args.input_dir}")
    print(f"ðŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"ðŸ¤– æ¨¡åž‹ç›®å½•: {args.model_dir}")
    
    start_time = time.time()
    
    # å¤šGPUå¹¶è¡Œæå–embeddings
    print("ðŸš€ å¼€å§‹å¤šGPUå¹¶è¡Œæå–embeddings...")
    
    # ä½¿ç”¨multiprocessing.spawnå¯åŠ¨å¤šä¸ªGPUè¿›ç¨‹
    mp.spawn(
        extract_embeddings_on_gpu,
        args=(world_size, args, audio_files),
        nprocs=world_size,
        join=True
    )
    
    # åˆå¹¶ç»Ÿè®¡ä¿¡æ¯
    merge_gpu_stats(args.output_dir, world_size)
    
    total_time = time.time() - start_time
    
    print(f"\nðŸŽ‰ å¤šGPU embeddingæå–å®Œæˆï¼")
    print(f"â±ï¸ æ€»è€—æ—¶: {total_time:.2f}ç§’")
    print(f"ðŸ“Š å¤„ç†æ•ˆçŽ‡: {len(audio_files)/total_time:.1f} ä¸ªæ–‡ä»¶/ç§’")
    print(f"ðŸ–¥ï¸ GPUåŠ é€Ÿæ¯”: é¢„è®¡æ¯”å•GPUå¿« {world_size:.1f}x")
    print(f"ðŸ’¾ ç»“æžœä¿å­˜åˆ°: {args.output_dir}")
    
    # æ˜¾ç¤ºç›®å½•ç»“æž„ç¤ºä¾‹
    print(f"\nðŸ“‚ è¾“å‡ºç›®å½•ç»“æž„ç¤ºä¾‹:")
    count = 0
    for root, dirs, files in os.walk(args.output_dir):
        if count >= 10:  # åªæ˜¾ç¤ºå‰10ä¸ªç¤ºä¾‹
            print("   ...")
            break
        for file in files[:3]:  # æ¯ä¸ªç›®å½•æœ€å¤šæ˜¾ç¤º3ä¸ªæ–‡ä»¶
            if file.endswith('.pkl'):
                rel_path = os.path.relpath(os.path.join(root, file), args.output_dir)
                print(f"   {rel_path}")
                count += 1
                if count >= 10:
                    break

if __name__ == "__main__":
    main()