#!/usr/bin/env python3
"""
åŸºäºé¢„æå–embeddingçš„è¯´è¯äººè¾¹ç•Œæ£€æµ‹è„šæœ¬
ä»embeddingæ–‡ä»¶ä¸­è¯»å–æ•°æ®è¿›è¡Œè¾¹ç•Œæ£€æµ‹å’Œè¯´è¯äººåˆ†å‰²
"""

import os
import sys
import json
import numpy as np
import argparse
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from tqdm import tqdm
import matplotlib.pyplot as plt
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.mixture import GaussianMixture
import seaborn as sns
from collections import defaultdict
import warnings
import time
import pickle
import shutil
warnings.filterwarnings('ignore')

def load_embedding_file(file_path):
    """åŠ è½½å•ä¸ªembeddingæ–‡ä»¶"""
    try:
        with open(file_path, 'rb') as f:
            data = pickle.load(f)
        return data['embedding'], data
    except Exception as e:
        print(f"âš ï¸ åŠ è½½embeddingæ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {e}")
        return None, None

def scan_embedding_files(embeddings_dir):
    """æ‰«æembeddingæ–‡ä»¶ç›®å½•ï¼ŒæŒ‰éŸ³é¢‘æ–‡ä»¶åæ’åº"""
    print(f"ğŸ“‚ æ‰«æembeddingæ–‡ä»¶: {embeddings_dir}")
    
    embedding_files = []
    
    for root, dirs, files in os.walk(embeddings_dir):
        for file in files:
            if file.endswith('.pkl'):
                full_path = os.path.join(root, file)
                rel_path = os.path.relpath(full_path, embeddings_dir)
                embedding_files.append({
                    'full_path': full_path,
                    'relative_path': rel_path,
                    'filename': file
                })
    
    # æŒ‰ç›¸å¯¹è·¯å¾„æ’åºï¼Œç¡®ä¿å¤„ç†é¡ºåºä¸åŸéŸ³é¢‘æ–‡ä»¶ä¸€è‡´
    embedding_files.sort(key=lambda x: x['relative_path'])
    
    print(f"ğŸ“Š æ‰¾åˆ° {len(embedding_files)} ä¸ªembeddingæ–‡ä»¶")
    return embedding_files

def load_all_embeddings(embedding_files):
    """åŠ è½½æ‰€æœ‰embeddingæ–‡ä»¶"""
    print("ğŸ¯ åŠ è½½æ‰€æœ‰embeddingæ–‡ä»¶...")
    
    embeddings = []
    audio_info = []
    failed_files = []
    
    for file_info in tqdm(embedding_files, desc="åŠ è½½embedding"):
        embedding, data = load_embedding_file(file_info['full_path'])
        
        if embedding is not None and data is not None:
            embeddings.append(embedding)
            audio_info.append({
                'original_path': data.get('original_path', ''),
                'relative_path': data.get('relative_path', file_info['relative_path']),
                'filename': data.get('filename', file_info['filename']),
                'embedding_file': file_info['full_path']
            })
        else:
            failed_files.append(file_info['full_path'])
    
    if embeddings:
        embeddings = np.array(embeddings)
    else:
        embeddings = np.array([]).reshape(0, -1)
    
    print(f"âœ… æˆåŠŸåŠ è½½ {len(embeddings)} ä¸ªembeddingï¼Œå¤±è´¥ {len(failed_files)} ä¸ª")
    
    return embeddings, audio_info, failed_files

def calculate_segment_centers(embeddings: np.ndarray, segment_size: int = 1000) -> List[np.ndarray]:
    """è®¡ç®—æ¯ä¸ªæ®µçš„èšç±»ä¸­å¿ƒ"""
    segment_centers = []
    n_segments = (len(embeddings) + segment_size - 1) // segment_size
    
    print(f"ğŸ“Š è®¡ç®— {n_segments} ä¸ªæ®µçš„èšç±»ä¸­å¿ƒ...")
    
    for i in range(n_segments):
        start_idx = i * segment_size
        end_idx = min((i + 1) * segment_size, len(embeddings))
        
        segment_embeddings = embeddings[start_idx:end_idx]
        center = np.mean(segment_embeddings, axis=0)
        segment_centers.append(center)
        
        print(f"  æ®µ {i+1}: [{start_idx}:{end_idx}] -> ä¸­å¿ƒè®¡ç®—å®Œæˆ")
    
    return segment_centers

def train_speaker_gmm(embeddings: np.ndarray, segment_name: str = "", n_components: int = 2, 
                     min_samples: int = 10) -> Optional[GaussianMixture]:
    """
    ä¸ºè¯´è¯äººæ®µè®­ç»ƒé«˜æ–¯æ··åˆæ¨¡å‹
    
    Args:
        embeddings: è¯´è¯äººçš„embeddingå‘é‡
        segment_name: æ®µåç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        n_components: é«˜æ–¯ç»„ä»¶æ•°é‡ï¼ˆé»˜è®¤2ä¸ªèšç±»ä¸­å¿ƒï¼‰
        min_samples: è®­ç»ƒGMMæ‰€éœ€çš„æœ€å°æ ·æœ¬æ•°
    
    Returns:
        è®­ç»ƒå¥½çš„GMMæ¨¡å‹ï¼Œå¦‚æœæ ·æœ¬ä¸è¶³æˆ–è®­ç»ƒå¤±è´¥åˆ™è¿”å›None
    """
    if len(embeddings) < min_samples:
        print(f"    âš ï¸ {segment_name} æ ·æœ¬æ•°é‡ä¸è¶³({len(embeddings)} < {min_samples})ï¼Œè·³è¿‡GMMè®­ç»ƒ")
        return None
    
    # å¦‚æœæ ·æœ¬æ•°å°‘äºç»„ä»¶æ•°çš„5å€ï¼Œå‡å°‘ç»„ä»¶æ•°
    if len(embeddings) < n_components * 5:
        n_components = max(1, len(embeddings) // 5)
        print(f"    ğŸ“‰ {segment_name} æ ·æœ¬æ•°é‡è¾ƒå°‘ï¼Œè°ƒæ•´GMMç»„ä»¶æ•°ä¸º {n_components}")
    
    try:
        gmm = GaussianMixture(
            n_components=n_components,
            covariance_type='full',
            random_state=42,
            max_iter=100,
            n_init=3
        )
        
        gmm.fit(embeddings)
        
        # æ£€æŸ¥æ¨¡å‹æ”¶æ•›æ€§
        if not gmm.converged_:
            print(f"    âš ï¸ {segment_name} GMMæœªæ”¶æ•›ï¼Œä½¿ç”¨ç®€å•å‡å€¼ä»£æ›¿")
            return None
            
        # è®¡ç®—BIC/AICæ¥è¯„ä¼°æ¨¡å‹è´¨é‡
        bic = gmm.bic(embeddings)
        aic = gmm.aic(embeddings)
        
        print(f"    âœ… {segment_name} GMMè®­ç»ƒæˆåŠŸ: {n_components}ç»„ä»¶, BIC={bic:.2f}, AIC={aic:.2f}")
        
        return gmm
        
    except Exception as e:
        print(f"    âŒ {segment_name} GMMè®­ç»ƒå¤±è´¥: {str(e)}")
        return None

def calculate_gmm_probability(embeddings: np.ndarray, gmm: GaussianMixture) -> float:
    """
    è®¡ç®—embeddingå‘é‡åœ¨GMMæ¨¡å‹ä¸‹çš„å¯¹æ•°æ¦‚ç‡
    
    Args:
        embeddings: å¾…è¯„ä¼°çš„embeddingå‘é‡
        gmm: è®­ç»ƒå¥½çš„GMMæ¨¡å‹
    
    Returns:
        å¹³å‡å¯¹æ•°æ¦‚ç‡ï¼ˆè¶Šå¤§è¡¨ç¤ºè¶ŠåŒ¹é…ï¼‰
    """
    if gmm is None or len(embeddings) == 0:
        return -np.inf
    
    try:
        log_probs = gmm.score_samples(embeddings)
        return np.mean(log_probs)
    except Exception as e:
        print(f"    âš ï¸ GMMæ¦‚ç‡è®¡ç®—å¤±è´¥: {str(e)}")
        return -np.inf

def calculate_boundary_gmm_scores(embeddings: np.ndarray, boundary_idx: int, 
                                left_gmm: GaussianMixture, right_gmm: GaussianMixture,
                                window_size: int = 5) -> Tuple[float, Dict]:
    """
    ä½¿ç”¨GMMæ¨¡å‹è®¡ç®—è¾¹ç•Œç‚¹çš„åˆ†å‰²è´¨é‡
    
    Args:
        embeddings: æ‰€æœ‰embeddingå‘é‡
        boundary_idx: è¾¹ç•Œç´¢å¼•
        left_gmm: å·¦æ®µçš„GMMæ¨¡å‹
        right_gmm: å³æ®µçš„GMMæ¨¡å‹
        window_size: è¾¹ç•Œé™„è¿‘ç”¨äºè¯„ä¼°çš„çª—å£å¤§å°
    
    Returns:
        (åˆ†å‰²è´¨é‡è¯„åˆ†, è¯¦ç»†ä¿¡æ¯)
    """
    # è·å–è¾¹ç•Œé™„è¿‘çš„embedding
    start_idx = max(0, boundary_idx - window_size)
    end_idx = min(len(embeddings), boundary_idx + window_size)
    
    left_embeddings = embeddings[start_idx:boundary_idx]
    right_embeddings = embeddings[boundary_idx:end_idx]
    
    if len(left_embeddings) == 0 or len(right_embeddings) == 0:
        return -np.inf, {'error': 'Empty segments'}
    
    # è®¡ç®—å·¦æ®µembeddingåœ¨å·¦GMMå’Œå³GMMä¸­çš„æ¦‚ç‡
    left_in_left_prob = calculate_gmm_probability(left_embeddings, left_gmm)
    left_in_right_prob = calculate_gmm_probability(left_embeddings, right_gmm)
    
    # è®¡ç®—å³æ®µembeddingåœ¨å·¦GMMå’Œå³GMMä¸­çš„æ¦‚ç‡
    right_in_left_prob = calculate_gmm_probability(right_embeddings, left_gmm)
    right_in_right_prob = calculate_gmm_probability(right_embeddings, right_gmm)
    
    # è®¡ç®—åˆ†å‰²è´¨é‡ï¼šæ­£ç¡®åˆ†ç±»çš„æ¦‚ç‡ - é”™è¯¯åˆ†ç±»çš„æ¦‚ç‡
    correct_assignment = left_in_left_prob + right_in_right_prob
    wrong_assignment = left_in_right_prob + right_in_left_prob
    
    separation_score = correct_assignment - wrong_assignment
    
    debug_info = {
        'left_in_left_prob': left_in_left_prob,
        'left_in_right_prob': left_in_right_prob,
        'right_in_left_prob': right_in_left_prob,
        'right_in_right_prob': right_in_right_prob,
        'correct_assignment': correct_assignment,
        'wrong_assignment': wrong_assignment,
        'separation_score': separation_score,
        'left_segment_size': len(left_embeddings),
        'right_segment_size': len(right_embeddings)
    }
    
    return separation_score, debug_info

def find_precise_boundary(embeddings: np.ndarray, theoretical_boundary: int, 
                         left_center: np.ndarray, right_center: np.ndarray,
                         boundary_window: int = 10, debug: bool = False) -> Tuple[int, Dict]:
    """åœ¨ç†è®ºåˆ†ç•Œç‚¹é™„è¿‘æ‰¾åˆ°ç²¾ç¡®çš„åˆ†ç•Œç‚¹"""
    start_idx = max(0, theoretical_boundary - boundary_window)
    end_idx = min(len(embeddings), theoretical_boundary + boundary_window + 1)
    
    if start_idx >= end_idx:
        return theoretical_boundary, {'validation': {'overall_accuracy': 0.0}}
    
    best_boundary = theoretical_boundary
    best_score = float('-inf')
    boundary_scores = []
    
    # åœ¨çª—å£å†…æœç´¢æœ€ä½³è¾¹ç•Œ
    for candidate_boundary in range(start_idx, end_idx):
        if candidate_boundary == 0 or candidate_boundary >= len(embeddings):
            continue
        
        # è®¡ç®—å·¦å³ä¸¤ä¾§ä¸å„è‡ªä¸­å¿ƒçš„ç›¸ä¼¼åº¦
        left_embeddings = embeddings[:candidate_boundary]
        right_embeddings = embeddings[candidate_boundary:]
        
        if len(left_embeddings) == 0 or len(right_embeddings) == 0:
            continue
        
        # è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°
        left_similarities = cosine_similarity(left_embeddings, [left_center]).flatten()
        right_similarities = cosine_similarity(right_embeddings, [right_center]).flatten()
        
        # æ€»åˆ†æ•° = å·¦ä¾§ç›¸ä¼¼åº¦å‡å€¼ + å³ä¾§ç›¸ä¼¼åº¦å‡å€¼
        score = np.mean(left_similarities) + np.mean(right_similarities)
        boundary_scores.append((candidate_boundary, score))
        
        if score > best_score:
            best_score = score
            best_boundary = candidate_boundary
    
    # è¾¹ç•ŒéªŒè¯
    validation_info = {}
    if best_boundary > 0 and best_boundary < len(embeddings):
        left_embeddings = embeddings[:best_boundary]
        right_embeddings = embeddings[best_boundary:]
        
        if len(left_embeddings) > 0 and len(right_embeddings) > 0:
            left_sims = cosine_similarity(left_embeddings, [left_center]).flatten()
            right_sims = cosine_similarity(right_embeddings, [right_center]).flatten()
            
            # è®¡ç®—åˆ†ç±»å‡†ç¡®ç‡
            left_correct = np.sum(left_sims > 0.5)
            right_correct = np.sum(right_sims > 0.5)
            total_correct = left_correct + right_correct
            total_samples = len(left_embeddings) + len(right_embeddings)
            
            validation_info = {
                'overall_accuracy': total_correct / total_samples if total_samples > 0 else 0,
                'left_accuracy': left_correct / len(left_embeddings),
                'right_accuracy': right_correct / len(right_embeddings),
                'left_avg_similarity': float(np.mean(left_sims)),
                'right_avg_similarity': float(np.mean(right_sims)),
                'boundary_score': float(best_score)
            }
    
    debug_info = {
        'theoretical_boundary': theoretical_boundary,
        'search_window': [start_idx, end_idx],
        'boundary_scores': boundary_scores if debug else [],
        'validation': validation_info
    }
    
    return best_boundary, debug_info

def detect_speaker_boundaries_gmm(embeddings: np.ndarray, audio_info: List[Dict], 
                                segment_size: int = 1000, boundary_window: int = 10, 
                                n_components: int = 2, boundary_exclusion_zone: int = 50,
                                debug: bool = False) -> Tuple[List[int], Dict]:
    """
    åŸºäºæ··åˆé«˜æ–¯æ¨¡å‹(GMM)çš„è¯´è¯äººè¾¹ç•Œæ£€æµ‹
    ä¸ºæ¯ä¸ªè¯´è¯äººæ®µè®­ç»ƒåŒ…å«å¤šä¸ªèšç±»ä¸­å¿ƒçš„GMMæ¨¡å‹ï¼Œç”¨æ¦‚ç‡æ¥è¡¡é‡è¾¹ç•ŒéŸ³é¢‘ä¸ç›¸é‚»è¯´è¯äººçš„å¥‘åˆåº¦
    
    Args:
        embeddings: éŸ³é¢‘embeddingå‘é‡
        audio_info: éŸ³é¢‘ä¿¡æ¯åˆ—è¡¨
        segment_size: æ¯æ®µçš„é¢„æœŸå¤§å°
        boundary_window: è¾¹ç•Œæœç´¢çª—å£å¤§å°
        n_components: GMMæ¨¡å‹çš„ç»„ä»¶æ•°é‡
        boundary_exclusion_zone: åœ¨è®­ç»ƒGMMæ—¶æ’é™¤è¾¹ç•Œé™„è¿‘å¤šå°‘ä¸ªéŸ³é¢‘ï¼ˆé¿å…æ··åˆç‰¹å¾å½±å“èšç±»ï¼‰
        debug: æ˜¯å¦å¼€å¯è°ƒè¯•æ¨¡å¼
    """
    
    if len(embeddings) <= segment_size:
        print("âš ï¸ éŸ³é¢‘æ–‡ä»¶æ•°é‡å°‘äºsegment_sizeï¼Œä¸è¿›è¡Œè¾¹ç•Œæ£€æµ‹")
        boundaries = [0, len(embeddings)]
        debug_info = {
            'total_segments': 1,
            'theoretical_boundaries': [],
            'boundary_debug_info': [],
            'gmm_algorithm': True
        }
        return boundaries, debug_info
    
    print(f"ğŸ­ å¼€å§‹åŸºäºGMMçš„è‡ªé€‚åº”è¾¹ç•Œæ£€æµ‹ï¼Œé¢„è®¡æ®µæ•°åŸºäº segment_size={segment_size}...")
    print(f"ğŸ§  æ¯ä¸ªè¯´è¯äººå°†è®­ç»ƒ {n_components} ä¸ªèšç±»ä¸­å¿ƒçš„GMMæ¨¡å‹")
    print(f"ğŸ“ ä½¿ç”¨è‡ªé€‚åº”ç®—æ³•ï¼šæ ¹æ®å®é™…è¾¹ç•Œé‡æ–°è®¡ç®—åç»­èµ·ç‚¹")
    print(f"ğŸš« è®­ç»ƒGMMæ—¶æ’é™¤è¾¹ç•Œé™„è¿‘ Â±{boundary_exclusion_zone} ä¸ªéŸ³é¢‘ï¼Œé¿å…æ··åˆç‰¹å¾å½±å“èšç±»")
    
    boundaries = [0]  # èµ·å§‹è¾¹ç•Œ
    boundary_debug_info = []
    theoretical_boundaries = []
    gmm_models = []  # å­˜å‚¨æ¯ä¸ªæ®µçš„GMMæ¨¡å‹
    
    # è‡ªé€‚åº”è¾¹ç•Œæ£€æµ‹ï¼šæ¯æ¬¡åŸºäºå‰ä¸€ä¸ªå®é™…è¾¹ç•Œè®¡ç®—ä¸‹ä¸€ä¸ªç†è®ºè¾¹ç•Œ
    current_start = 0
    segment_index = 0
    
    while current_start + segment_size < len(embeddings):
        # è®¡ç®—å½“å‰ç†è®ºè¾¹ç•Œä½ç½®ï¼ˆåŸºäºå‰ä¸€ä¸ªå®é™…è¾¹ç•Œï¼‰
        theoretical_boundary = current_start + segment_size
        theoretical_boundaries.append(theoretical_boundary)
        
        # ç¡®ä¿ä¸è¶…å‡ºæ•°ç»„èŒƒå›´
        if theoretical_boundary >= len(embeddings):
            break
        
        print(f"  ğŸ¯ æ£€æµ‹è¾¹ç•Œ {segment_index+1} (ç†è®ºä½ç½®: {theoretical_boundary})")
        
        # è®­ç»ƒå½“å‰æ®µçš„GMMæ¨¡å‹ - æ’é™¤è¾¹ç•Œé™„è¿‘çš„éŸ³é¢‘
        current_segment_end = min(theoretical_boundary, len(embeddings))
        # æ’é™¤é è¿‘è¾¹ç•Œçš„éŸ³é¢‘æ ·æœ¬ï¼Œé¿å…æ··åˆç‰¹å¾å½±å“èšç±»
        # ç¡®ä¿è‡³å°‘ä¿ç•™ä¸€åŠçš„æ•°æ®ç”¨äºè®­ç»ƒ
        max_exclusion = (current_segment_end - current_start) // 2
        actual_exclusion = min(boundary_exclusion_zone, max_exclusion)
        left_train_end = max(current_start, current_segment_end - actual_exclusion)
        left_embeddings = embeddings[current_start:left_train_end]
        
        exclusion_info = f"(æ’é™¤è¾¹ç•Œ {actual_exclusion}/{boundary_exclusion_zone})" if actual_exclusion < boundary_exclusion_zone else ""
        print(f"    ğŸ—ï¸ è®­ç»ƒå·¦æ®µGMMæ¨¡å‹ (å®Œæ•´èŒƒå›´: [{current_start}:{current_segment_end}], è®­ç»ƒèŒƒå›´: [{current_start}:{left_train_end}], {len(left_embeddings)} ä¸ªæ ·æœ¬) {exclusion_info}")
        left_gmm = train_speaker_gmm(
            left_embeddings, 
            segment_name=f"å·¦æ®µ{segment_index+1}", 
            n_components=n_components
        )
        
        # è®­ç»ƒä¸‹ä¸€æ®µçš„GMMæ¨¡å‹ - æ’é™¤è¾¹ç•Œé™„è¿‘çš„éŸ³é¢‘
        next_segment_start = theoretical_boundary
        next_segment_end = min(next_segment_start + segment_size, len(embeddings))
        # æ’é™¤é è¿‘è¾¹ç•Œçš„éŸ³é¢‘æ ·æœ¬ï¼Œç¡®ä¿è‡³å°‘ä¿ç•™ä¸€åŠçš„æ•°æ®ç”¨äºè®­ç»ƒ
        max_exclusion = (next_segment_end - next_segment_start) // 2
        actual_exclusion = min(boundary_exclusion_zone, max_exclusion)
        right_train_start = min(next_segment_end, next_segment_start + actual_exclusion)
        right_embeddings = embeddings[right_train_start:next_segment_end]
        
        exclusion_info = f"(æ’é™¤è¾¹ç•Œ {actual_exclusion}/{boundary_exclusion_zone})" if actual_exclusion < boundary_exclusion_zone else ""
        print(f"    ğŸ—ï¸ è®­ç»ƒå³æ®µGMMæ¨¡å‹ (å®Œæ•´èŒƒå›´: [{next_segment_start}:{next_segment_end}], è®­ç»ƒèŒƒå›´: [{right_train_start}:{next_segment_end}], {len(right_embeddings)} ä¸ªæ ·æœ¬) {exclusion_info}")
        right_gmm = train_speaker_gmm(
            right_embeddings, 
            segment_name=f"å³æ®µ{segment_index+2}", 
            n_components=n_components
        )
        
        # å¦‚æœGMMè®­ç»ƒå¤±è´¥ï¼Œå›é€€åˆ°ä½™å¼¦ç›¸ä¼¼åº¦æ–¹æ³•
        if left_gmm is None or right_gmm is None:
            print(f"    âš ï¸ GMMè®­ç»ƒå¤±è´¥ï¼Œå›é€€åˆ°ä½™å¼¦ç›¸ä¼¼åº¦æ–¹æ³•")
            left_center = np.mean(left_embeddings, axis=0)
            right_center = np.mean(right_embeddings, axis=0)
            
            precise_boundary, debug_info = find_precise_boundary(
                embeddings, theoretical_boundary, left_center, right_center, 
                boundary_window, debug
            )
            debug_info['fallback_to_cosine'] = True
        else:
            # ä½¿ç”¨GMMæ¨¡å‹è¿›è¡Œç²¾ç¡®è¾¹ç•Œæ£€æµ‹
            print(f"    ğŸ” ä½¿ç”¨GMMæ¨¡å‹æœç´¢ç²¾ç¡®è¾¹ç•Œ (çª—å£: Â±{boundary_window})")
            precise_boundary, debug_info = find_precise_boundary_gmm(
                embeddings, theoretical_boundary, left_gmm, right_gmm, 
                boundary_window, debug
            )
            debug_info['fallback_to_cosine'] = False
        
        boundaries.append(precise_boundary)
        debug_info['segment_index'] = segment_index + 1
        debug_info['current_start'] = current_start
        debug_info['theoretical_boundary'] = theoretical_boundary
        debug_info['actual_segment_size'] = precise_boundary - current_start
        boundary_debug_info.append(debug_info)
        
        # å­˜å‚¨GMMæ¨¡å‹
        gmm_models.append({
            'segment_index': segment_index + 1,
            'left_gmm': left_gmm,
            'right_gmm': right_gmm,
            'boundaries': [current_start, precise_boundary]
        })
        
        # è¾“å‡ºè¯¦ç»†ä¿¡æ¯
        actual_segment_size = precise_boundary - current_start
        offset = precise_boundary - theoretical_boundary
        
        if 'validation' in debug_info and 'overall_accuracy' in debug_info['validation']:
            accuracy = debug_info['validation']['overall_accuracy']
            print(f"    âœ… ç²¾ç¡®è¾¹ç•Œ: {precise_boundary}")
            print(f"    ğŸ“Š å®é™…æ®µå¤§å°: {actual_segment_size} (ç›®æ ‡: {segment_size}, åå·®: {actual_segment_size - segment_size})")
            print(f"    ğŸ“ è¾¹ç•Œåç§»: {offset}, å‡†ç¡®ç‡: {accuracy:.2%}")
        else:
            print(f"    âœ… ç²¾ç¡®è¾¹ç•Œ: {precise_boundary} (åç§»: {offset})")
            print(f"    ğŸ“Š å®é™…æ®µå¤§å°: {actual_segment_size} (ç›®æ ‡: {segment_size}, åå·®: {actual_segment_size - segment_size})")
        
        # æ›´æ–°ä¸‹ä¸€è½®çš„èµ·ç‚¹ä¸ºå½“å‰æ£€æµ‹åˆ°çš„å®é™…è¾¹ç•Œ
        current_start = precise_boundary
        segment_index += 1
        
        # é˜²æ­¢æ— é™å¾ªç¯ - ä½¿ç”¨æ›´åˆç†çš„ç»ˆæ­¢æ¡ä»¶
        if segment_index > 10000:  # å¤§å¹…æé«˜é™åˆ¶åˆ°10000ä¸ªæ®µ
            print("âš ï¸ è¾¾åˆ°æœ€å¤§æ®µæ•°é™åˆ¶(10000)ï¼Œåœæ­¢æ£€æµ‹")
            break
    
    boundaries.append(len(embeddings))  # ç»“æŸè¾¹ç•Œ
    
    # ç»Ÿè®¡ä¿¡æ¯
    actual_segments = len(boundaries) - 1
    print(f"\nğŸ“Š GMMè¾¹ç•Œæ£€æµ‹ç»Ÿè®¡ï¼š")
    print(f"   å®é™…æ®µæ•°: {actual_segments}")
    print(f"   GMMç»„ä»¶æ•°: {n_components}")
    print(f"   æ®µå¤§å°ç»Ÿè®¡:")
    
    for i in range(len(boundaries) - 1):
        start_idx = boundaries[i]
        end_idx = boundaries[i + 1]
        segment_size_actual = end_idx - start_idx
        print(f"     æ®µ {i+1}: {segment_size_actual} ä¸ªæ–‡ä»¶ (èŒƒå›´: [{start_idx}:{end_idx}])")
    
    combined_debug = {
        'total_segments': actual_segments,
        'theoretical_boundaries': theoretical_boundaries,
        'boundary_debug_info': boundary_debug_info,
        'gmm_algorithm': True,
        'gmm_components': n_components,
        'gmm_models': gmm_models,
        'target_segment_size': segment_size,
        'actual_segment_sizes': [boundaries[i+1] - boundaries[i] for i in range(len(boundaries)-1)]
    }
    
    return boundaries, combined_debug

def find_precise_boundary_gmm(embeddings: np.ndarray, theoretical_boundary: int, 
                             left_gmm: GaussianMixture, right_gmm: GaussianMixture,
                             boundary_window: int = 10, debug: bool = False) -> Tuple[int, Dict]:
    """ä½¿ç”¨GMMæ¨¡å‹åœ¨ç†è®ºåˆ†ç•Œç‚¹é™„è¿‘æ‰¾åˆ°ç²¾ç¡®çš„åˆ†ç•Œç‚¹"""
    start_idx = max(0, theoretical_boundary - boundary_window)
    end_idx = min(len(embeddings), theoretical_boundary + boundary_window + 1)
    
    if start_idx >= end_idx:
        return theoretical_boundary, {'validation': {'overall_accuracy': 0.0}}
    
    best_boundary = theoretical_boundary
    best_score = float('-inf')
    best_debug_info = {}
    
    print(f"      ğŸ” GMMè¾¹ç•Œæœç´¢èŒƒå›´: [{start_idx}:{end_idx}]")
    
    scores = []
    for boundary_idx in range(start_idx, end_idx):
        score, debug_info = calculate_boundary_gmm_scores(
            embeddings, boundary_idx, left_gmm, right_gmm, window_size=5
        )
        
        scores.append(score)
        
        if debug:
            print(f"        ä½ç½® {boundary_idx}: GMMåˆ†ç¦»åº¦={score:.4f}")
        
        if score > best_score:
            best_score = score
            best_boundary = boundary_idx
            best_debug_info = debug_info
    
    # è®¡ç®—éªŒè¯ä¿¡æ¯
    validation_info = {
        'overall_accuracy': min(1.0, max(0.0, (best_score + 10) / 20)),  # å½’ä¸€åŒ–åˆ°0-1
        'separation_score': best_score,
        'search_range': [start_idx, end_idx],
        'scores': scores
    }
    
    best_debug_info.update({
        'theoretical_boundary': theoretical_boundary,
        'best_boundary': best_boundary,
        'best_score': best_score,
        'search_window': boundary_window,
        'method': 'GMM',
        'validation': validation_info
    })
    
    print(f"      âœ… GMMæœ€ä½³è¾¹ç•Œ: {best_boundary} (åˆ†ç¦»åº¦: {best_score:.4f})")
    
    return best_boundary, best_debug_info

def detect_speaker_boundaries(embeddings: np.ndarray, audio_info: List[Dict], 
                            segment_size: int = 1000, boundary_window: int = 10, 
                            debug: bool = False) -> Tuple[List[int], Dict]:
    """æ£€æµ‹è¯´è¯äººè¾¹ç•Œï¼ˆåŸºäºç´¯ç§¯å®é™…è¾¹ç•Œçš„è‡ªé€‚åº”ç®—æ³•ï¼‰"""
    
    if len(embeddings) <= segment_size:
        print("âš ï¸ éŸ³é¢‘æ–‡ä»¶æ•°é‡å°‘äºsegment_sizeï¼Œä¸è¿›è¡Œè¾¹ç•Œæ£€æµ‹")
        boundaries = [0, len(embeddings)]
        debug_info = {
            'total_segments': 1,
            'theoretical_boundaries': [],
            'boundary_debug_info': []
        }
        return boundaries, debug_info
    
    # è®¡ç®—æ®µä¸­å¿ƒï¼ˆç”¨äºåˆå§‹å‚è€ƒï¼‰
    segment_centers = calculate_segment_centers(embeddings, segment_size)
    n_segments = len(segment_centers)
    
    print(f"ğŸ” å¼€å§‹è‡ªé€‚åº”è¾¹ç•Œæ£€æµ‹ï¼Œé¢„è®¡ {n_segments} ä¸ªæ®µ...")
    print(f"ğŸ“ ä½¿ç”¨è‡ªé€‚åº”ç®—æ³•ï¼šæ ¹æ®å®é™…è¾¹ç•Œé‡æ–°è®¡ç®—åç»­èµ·ç‚¹")
    
    boundaries = [0]  # èµ·å§‹è¾¹ç•Œ
    boundary_debug_info = []
    theoretical_boundaries = []
    
    # è‡ªé€‚åº”è¾¹ç•Œæ£€æµ‹ï¼šæ¯æ¬¡åŸºäºå‰ä¸€ä¸ªå®é™…è¾¹ç•Œè®¡ç®—ä¸‹ä¸€ä¸ªç†è®ºè¾¹ç•Œ
    current_start = 0
    segment_index = 0
    
    while current_start + segment_size < len(embeddings):
        # è®¡ç®—å½“å‰ç†è®ºè¾¹ç•Œä½ç½®ï¼ˆåŸºäºå‰ä¸€ä¸ªå®é™…è¾¹ç•Œï¼‰
        theoretical_boundary = current_start + segment_size
        theoretical_boundaries.append(theoretical_boundary)
        
        # ç¡®ä¿ä¸è¶…å‡ºæ•°ç»„èŒƒå›´
        if theoretical_boundary >= len(embeddings):
            break
        
        # é‡æ–°è®¡ç®—å½“å‰æ®µå’Œä¸‹ä¸€æ®µçš„ä¸­å¿ƒ
        # å½“å‰æ®µï¼šä»ä¸Šä¸€ä¸ªå®é™…è¾¹ç•Œåˆ°ç†è®ºè¾¹ç•Œ
        current_segment_end = min(theoretical_boundary, len(embeddings))
        left_embeddings = embeddings[current_start:current_segment_end]
        left_center = np.mean(left_embeddings, axis=0)
        
        # ä¸‹ä¸€æ®µï¼šä»ç†è®ºè¾¹ç•Œåˆ°ç†è®ºè¾¹ç•Œ+segment_size
        next_segment_start = theoretical_boundary
        next_segment_end = min(next_segment_start + segment_size, len(embeddings))
        right_embeddings = embeddings[next_segment_start:next_segment_end]
        right_center = np.mean(right_embeddings, axis=0)
        
        print(f"  ğŸ¯ æ£€æµ‹è¾¹ç•Œ {segment_index+1} (ç†è®ºä½ç½®: {theoretical_boundary})")
        print(f"    å·¦æ®µèŒƒå›´: [{current_start}:{current_segment_end}] ({current_segment_end - current_start} ä¸ªæ–‡ä»¶)")
        print(f"    å³æ®µèŒƒå›´: [{next_segment_start}:{next_segment_end}] ({next_segment_end - next_segment_start} ä¸ªæ–‡ä»¶)")
        
        # åœ¨ç†è®ºè¾¹ç•Œé™„è¿‘æœç´¢ç²¾ç¡®è¾¹ç•Œ
        precise_boundary, debug_info = find_precise_boundary(
            embeddings, theoretical_boundary, left_center, right_center, 
            boundary_window, debug
        )
        
        boundaries.append(precise_boundary)
        debug_info['segment_index'] = segment_index + 1
        debug_info['current_start'] = current_start
        debug_info['theoretical_boundary'] = theoretical_boundary
        debug_info['actual_segment_size'] = precise_boundary - current_start
        boundary_debug_info.append(debug_info)
        
        accuracy = debug_info['validation']['overall_accuracy']
        actual_segment_size = precise_boundary - current_start
        offset = precise_boundary - theoretical_boundary
        
        print(f"    âœ… ç²¾ç¡®è¾¹ç•Œ: {precise_boundary}")
        print(f"    ğŸ“Š å®é™…æ®µå¤§å°: {actual_segment_size} (ç›®æ ‡: {segment_size}, åå·®: {actual_segment_size - segment_size})")
        print(f"    ğŸ“ è¾¹ç•Œåç§»: {offset}, å‡†ç¡®ç‡: {accuracy:.2%}")
        
        # æ›´æ–°ä¸‹ä¸€è½®çš„èµ·ç‚¹ä¸ºå½“å‰æ£€æµ‹åˆ°çš„å®é™…è¾¹ç•Œ
        current_start = precise_boundary
        segment_index += 1
        
        # é˜²æ­¢æ— é™å¾ªç¯ - ä½¿ç”¨æ›´åˆç†çš„ç»ˆæ­¢æ¡ä»¶
        if segment_index > 10000:  # å¤§å¹…æé«˜é™åˆ¶åˆ°10000ä¸ªæ®µ
            print("âš ï¸ è¾¾åˆ°æœ€å¤§æ®µæ•°é™åˆ¶(10000)ï¼Œåœæ­¢æ£€æµ‹")
            break
    
    boundaries.append(len(embeddings))  # ç»“æŸè¾¹ç•Œ
    
    # ç»Ÿè®¡ä¿¡æ¯
    actual_segments = len(boundaries) - 1
    print(f"\nğŸ“Š è¾¹ç•Œæ£€æµ‹ç»Ÿè®¡ï¼š")
    print(f"   é¢„è®¡æ®µæ•°: {n_segments}")
    print(f"   å®é™…æ®µæ•°: {actual_segments}")
    print(f"   æ®µå¤§å°ç»Ÿè®¡:")
    
    for i in range(len(boundaries) - 1):
        start_idx = boundaries[i]
        end_idx = boundaries[i + 1]
        segment_size_actual = end_idx - start_idx
        print(f"     æ®µ {i+1}: {segment_size_actual} ä¸ªæ–‡ä»¶ (èŒƒå›´: [{start_idx}:{end_idx}])")
    
    combined_debug = {
        'total_segments': actual_segments,
        'theoretical_boundaries': theoretical_boundaries,
        'boundary_debug_info': boundary_debug_info,
        'adaptive_algorithm': True,
        'target_segment_size': segment_size,
        'actual_segment_sizes': [boundaries[i+1] - boundaries[i] for i in range(len(boundaries)-1)]
    }
    
    return boundaries, combined_debug

def save_results(boundaries: List[int], debug_info: Dict, audio_info: List[Dict], output_dir: str) -> Dict:
    """ä¿å­˜æ£€æµ‹ç»“æœå¹¶åˆ†å‰²éŸ³é¢‘æ–‡ä»¶"""
    print("ğŸ’¾ ä¿å­˜ç»“æœå¹¶åˆ†å‰²éŸ³é¢‘æ–‡ä»¶...")
    
    speakers = []
    
    for i in range(len(boundaries) - 1):
        start_idx = boundaries[i]
        end_idx = boundaries[i + 1]
        file_count = end_idx - start_idx
        
        speaker_info = {
            'speaker_id': f'speaker_{i+1:03d}',
            'start_index': start_idx,
            'end_index': end_idx,
            'file_count': file_count,
            'audio_files': []
        }
        
        # åˆ›å»ºè¯´è¯äººç›®å½•
        speaker_dir = os.path.join(output_dir, speaker_info['speaker_id'])
        os.makedirs(speaker_dir, exist_ok=True)
        
        # å¤åˆ¶æˆ–é“¾æ¥éŸ³é¢‘æ–‡ä»¶
        for j in range(start_idx, min(end_idx, len(audio_info))):
            audio_data = audio_info[j]
            original_path = audio_data['original_path']
            filename = audio_data['filename']
            
            if original_path and os.path.exists(original_path):
                # è·å–åŸå§‹éŸ³é¢‘æ–‡ä»¶å
                original_filename = os.path.basename(original_path)
                dst_file = os.path.join(speaker_dir, original_filename)
                
                try:
                    # å¤åˆ¶éŸ³é¢‘æ–‡ä»¶
                    shutil.copy2(original_path, dst_file)
                    speaker_info['audio_files'].append(original_filename)
                except Exception as e:
                    print(f"âš ï¸ å¤åˆ¶æ–‡ä»¶å¤±è´¥: {original_path} -> {dst_file}, é”™è¯¯: {e}")
            else:
                print(f"âš ï¸ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨æˆ–è·¯å¾„ä¸ºç©º: {original_path}")
        
        speakers.append(speaker_info)
    
    def make_json_serializable(obj):
        """é€’å½’åœ°å°†å¯¹è±¡è½¬æ¢ä¸ºJSONå¯åºåˆ—åŒ–çš„æ ¼å¼"""
        if isinstance(obj, dict):
            result = {}
            for k, v in obj.items():
                if k == 'gmm_models' and isinstance(v, list):
                    # ç‰¹æ®Šå¤„ç†GMMæ¨¡å‹åˆ—è¡¨
                    gmm_summary = []
                    for model_info in v:
                        summary = {
                            'segment_index': model_info.get('segment_index'),
                            'boundaries': model_info.get('boundaries'),
                            'left_gmm_available': model_info.get('left_gmm') is not None,
                            'right_gmm_available': model_info.get('right_gmm') is not None
                        }
                        # å¦‚æœGMMæ¨¡å‹å­˜åœ¨ï¼Œæ·»åŠ ä¸€äº›åŸºæœ¬ä¿¡æ¯
                        if model_info.get('left_gmm') is not None:
                            summary['left_gmm_components'] = model_info['left_gmm'].n_components
                        if model_info.get('right_gmm') is not None:
                            summary['right_gmm_components'] = model_info['right_gmm'].n_components
                        gmm_summary.append(summary)
                    result[k] = gmm_summary
                else:
                    result[k] = make_json_serializable(v)
            return result
        elif isinstance(obj, list):
            return [make_json_serializable(item) for item in obj]
        elif isinstance(obj, tuple):
            return [make_json_serializable(item) for item in obj]
        elif isinstance(obj, np.ndarray):
            return obj.tolist()  # å°†numpyæ•°ç»„è½¬æ¢ä¸ºPythonåˆ—è¡¨
        elif isinstance(obj, (np.integer, np.floating)):
            return obj.item()  # å°†numpyæ ‡é‡è½¬æ¢ä¸ºPythonæ ‡é‡
        elif hasattr(obj, '__dict__') and not isinstance(obj, (str, int, float, bool, type(None))):
            # å¯¹äºå…¶ä»–å¤æ‚å¯¹è±¡ï¼Œè¿”å›ç±»åä¿¡æ¯
            return f"<{obj.__class__.__name__} object (not serializable)>"
        else:
            return obj

    # åˆ›å»ºJSONå®‰å…¨çš„debug_infoï¼ˆç§»é™¤ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡ï¼‰
    json_safe_debug_info = make_json_serializable(debug_info)

    result = {
        'boundaries': boundaries,
        'speakers': speakers,
        'debug_info': json_safe_debug_info,
        'total_audio_files': len(audio_info),
        'detected_speakers': len(speakers)
    }
    
    # ä¿å­˜JSONç»“æœ
    result_file = os.path.join(output_dir, 'speaker_boundary_detection_result.json')
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“Š ç»“æœå·²ä¿å­˜: {result_file}")
    print(f"   æ£€æµ‹åˆ° {len(speakers)} ä¸ªè¯´è¯äºº")
    print(f"   è¾¹ç•Œä½ç½®: {boundaries}")
    
    # æ˜¾ç¤ºæ¯ä¸ªè¯´è¯äººçš„æ–‡ä»¶æ•°é‡
    for speaker in speakers:
        print(f"   {speaker['speaker_id']}: {speaker['file_count']} ä¸ªéŸ³é¢‘æ–‡ä»¶")
    
    return result

def plot_boundary_visualization(embeddings: np.ndarray, boundaries: List[int], 
                               debug_info: Dict, output_file: str):
    """ç”Ÿæˆè¾¹ç•Œæ£€æµ‹å¯è§†åŒ–å›¾"""
    try:
        if len(embeddings) == 0:
            print("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„embeddingæ•°æ®ï¼Œè·³è¿‡å¯è§†åŒ–")
            return
        
        plt.figure(figsize=(15, 10))
        
        # è®¡ç®—PCAé™ç»´ç”¨äºå¯è§†åŒ–
        if embeddings.shape[1] > 2:
            from sklearn.decomposition import PCA
            pca = PCA(n_components=2)
            embeddings_2d = pca.fit_transform(embeddings)
        else:
            embeddings_2d = embeddings
        
        # ç»˜åˆ¶embeddingsæ•£ç‚¹å›¾
        plt.subplot(2, 1, 1)
        scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], 
                            c=range(len(embeddings_2d)), cmap='tab10', alpha=0.6, s=10)
        plt.colorbar(scatter, label='File Index')
        plt.title('Speaker Embeddings Visualization (PCA)')
        plt.xlabel('PCA Component 1')
        plt.ylabel('PCA Component 2')
        
        # ç»˜åˆ¶è¾¹ç•Œçº¿
        for i, boundary in enumerate(boundaries[1:-1], 1):
            if boundary < len(embeddings):
                point = embeddings_2d[boundary]
                plt.axvline(x=point[0], color='red', linestyle='--', alpha=0.7, 
                          label=f'Boundary {i}' if i == 1 else "")
        
        if len(boundaries) > 2:
            plt.legend()
        
        # ç»˜åˆ¶ç›¸ä¼¼åº¦æ›²çº¿
        plt.subplot(2, 1, 2)
        if len(embeddings) > 1:
            similarities = []
            for i in range(len(embeddings) - 1):
                sim = cosine_similarity([embeddings[i]], [embeddings[i + 1]])[0][0]
                similarities.append(sim)
            
            plt.plot(similarities, alpha=0.7, linewidth=1)
            plt.title('Adjacent File Similarity')
            plt.xlabel('File Index')
            plt.ylabel('Cosine Similarity')
            
            # æ ‡è®°è¾¹ç•Œä½ç½®
            for boundary in boundaries[1:-1]:
                if boundary < len(similarities):
                    plt.axvline(x=boundary, color='red', linestyle='--', alpha=0.7)
                    plt.text(boundary, max(similarities) * 0.9, f'B{boundary}', 
                           rotation=90, ha='right', va='top')
        
        plt.tight_layout()
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"ğŸ“Š å¯è§†åŒ–å›¾å·²ä¿å­˜: {output_file}")
        
    except Exception as e:
        print(f"âš ï¸ ç”Ÿæˆå¯è§†åŒ–å›¾å¤±è´¥: {e}")

def main():
    parser = argparse.ArgumentParser(description="åŸºäºembeddingçš„è¯´è¯äººè¾¹ç•Œæ£€æµ‹")
    parser.add_argument('--embeddings_dir', type=str, default="/root/group-shared/voiceprint/data/speech/speech_enhancement/child-2.07M/wav_embeddings_samresnet100",
                       help='embeddingæ–‡ä»¶ç›®å½•è·¯å¾„')
    parser.add_argument('--output_dir', type=str, default="/root/group-shared/voiceprint/data/speech/speech_enhancement/child-2.07M/wav_embeddings_samresnet100_boundaries",
                       help='è¾“å‡ºç›®å½•è·¯å¾„')
    parser.add_argument('--segment_size', type=int, default=1000,
                       help='æ¯æ®µçš„é¢„æœŸå¤§å°ï¼ˆé»˜è®¤1000ï¼‰')
    parser.add_argument('--boundary_window', type=int, default=20,
                       help='è¾¹ç•Œæœç´¢çª—å£å¤§å°ï¼ˆé»˜è®¤10ï¼‰')
    parser.add_argument('--debug', action='store_true',
                       help='å¼€å¯è°ƒè¯•æ¨¡å¼')
    parser.add_argument('--use_gmm', action='store_true', default=True,
                       help='ä½¿ç”¨æ··åˆé«˜æ–¯æ¨¡å‹(GMM)è¿›è¡Œè¾¹ç•Œæ£€æµ‹')
    parser.add_argument('--gmm_components', type=int, default=1,
                       help='GMMæ¨¡å‹çš„ç»„ä»¶æ•°é‡ï¼ˆé»˜è®¤1ä¸ªèšç±»ä¸­å¿ƒï¼‰')
    parser.add_argument('--boundary_exclusion_zone', type=int, default=20,
                       help='è®­ç»ƒGMMæ—¶æ’é™¤è¾¹ç•Œé™„è¿‘å¤šå°‘ä¸ªéŸ³é¢‘ï¼ˆé»˜è®¤50ï¼Œé¿å…æ··åˆç‰¹å¾å½±å“èšç±»ï¼‰')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥ç›®å½•
    if not os.path.exists(args.embeddings_dir):
        print(f"âŒ embeddingç›®å½•ä¸å­˜åœ¨: {args.embeddings_dir}")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    
    print(f"ğŸ¯ å¼€å§‹åŸºäºembeddingçš„è¯´è¯äººè¾¹ç•Œæ£€æµ‹")
    print(f"ğŸ“ Embeddingç›®å½•: {args.embeddings_dir}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"ğŸ“ æ®µå¤§å°: {args.segment_size}")
    print(f"ğŸ”§ è¾¹ç•Œçª—å£: Â±{args.boundary_window}")
    print(f"ğŸ› è°ƒè¯•æ¨¡å¼: {args.debug}")
    if args.use_gmm:
        print(f"ğŸ­ æ£€æµ‹ç®—æ³•: æ··åˆé«˜æ–¯æ¨¡å‹ (GMM)")
        print(f"ğŸ§  GMMç»„ä»¶æ•°: {args.gmm_components}")
        print(f"ğŸš« è¾¹ç•Œæ’é™¤åŒºåŸŸ: Â±{args.boundary_exclusion_zone} ä¸ªéŸ³é¢‘ï¼ˆèšç±»æ—¶æ’é™¤ï¼‰")
    else:
        print(f"ğŸ¯ æ£€æµ‹ç®—æ³•: ä½™å¼¦ç›¸ä¼¼åº¦")
    print("")
    
    start_time = time.time()
    
    # æ‰«æembeddingæ–‡ä»¶
    embedding_files = scan_embedding_files(args.embeddings_dir)
    
    if not embedding_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°embeddingæ–‡ä»¶")
        return
    
    # åŠ è½½æ‰€æœ‰embeddings
    embeddings, audio_info, failed_files = load_all_embeddings(embedding_files)
    
    if len(embeddings) == 0:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„embeddingæ•°æ®")
        return
    
    print(f"âœ… æˆåŠŸåŠ è½½ {len(embeddings)} ä¸ªembedding")
    print(f"   ç¬¬ä¸€ä¸ªæ–‡ä»¶: {audio_info[0]['filename'] if audio_info else 'N/A'}")
    print(f"   æœ€åä¸€ä¸ªæ–‡ä»¶: {audio_info[-1]['filename'] if audio_info else 'N/A'}")
    print(f"   Embeddingç»´åº¦: {embeddings.shape[1]}")
    
    # æ£€æµ‹è¯´è¯äººè¾¹ç•Œ
    print("\nğŸ” å¼€å§‹è¯´è¯äººè¾¹ç•Œæ£€æµ‹...")
    if args.use_gmm:
        boundaries, detection_debug = detect_speaker_boundaries_gmm(
            embeddings, audio_info, args.segment_size, args.boundary_window, 
            args.gmm_components, args.boundary_exclusion_zone, args.debug
        )
    else:
        boundaries, detection_debug = detect_speaker_boundaries(
            embeddings, audio_info, args.segment_size, args.boundary_window, args.debug
        )
    
    # åˆå¹¶è°ƒè¯•ä¿¡æ¯
    combined_debug = {
        'detection': detection_debug,
        'processing_time': time.time() - start_time,
        'failed_files': failed_files,
        'total_embeddings': len(embeddings)
    }
    
    # ä¿å­˜ç»“æœ
    result = save_results(boundaries, combined_debug, audio_info, args.output_dir)
    
    # ç”Ÿæˆå¯è§†åŒ–
    visualization_file = os.path.join(args.output_dir, 'boundary_detection_visualization.png')
    plot_boundary_visualization(embeddings, boundaries, combined_debug, visualization_file)
    
    total_time = time.time() - start_time
    print(f"\nğŸ‰ è¾¹ç•Œæ£€æµ‹å®Œæˆï¼")
    print(f"â±ï¸ æ€»è€—æ—¶: {total_time:.2f}ç§’")
    print(f"ğŸ¯ æ£€æµ‹åˆ° {len(boundaries) - 1} ä¸ªè¯´è¯äºº")
    print(f"ğŸ“Š å¤„ç†æ•ˆç‡: {len(embeddings)/total_time:.1f} ä¸ªæ–‡ä»¶/ç§’")
    print(f"ğŸ’¾ ç»“æœä¿å­˜åˆ°: {args.output_dir}")

if __name__ == "__main__":
    main()